import cv2
import numpy as np

# Load YOLO model and COCO class labels
net = cv2.dnn.readNet(r"C:\Users\yugan\Downloads\yolov3.cfg", r"C:\Users\yugan\Downloads\yolov3.weights")
with open(r"C:\Users\yugan\Downloads\coco.names", 'r') as f:
    classes = f.read().strip().split('\n')

# Filter only vehicle classes
vehicle_classes = ["car", "motorbike", "bus", "truck"]

def detect_lanes(frame):
    """Detects lane markings in the frame and draws them."""
    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
    blur = cv2.GaussianBlur(gray, (5, 5), 0)
    edges = cv2.Canny(blur, 50, 150)

    height, width = frame.shape[:2]
    roi_vertices = np.array([[(0, height), (width, height), (width * 0.8, height * 0.6), (width * 0.2, height * 0.6)]], dtype=np.int32)
    mask = np.zeros_like(edges)
    cv2.fillPoly(mask, roi_vertices, 255)
    masked_edges = cv2.bitwise_and(edges, mask)

    # Detect lines using Hough Transform
    lines = cv2.HoughLinesP(masked_edges, 1, np.pi / 180, threshold=50, minLineLength=100, maxLineGap=50)
    
    if lines is not None:
        for line in lines:
            x1, y1, x2, y2 = line[0]
            cv2.line(frame, (x1, y1), (x2, y2), (0, 255, 255), 2)  # Yellow line for lanes

    return frame

def detect_vehicles_and_accidents(video_path):
    cap = cv2.VideoCapture(video_path)
    previous_bboxes = []
    skip_frames = 1  # Change this value to skip more frames (e.g., 1 means process every frame, 2 means every second frame)
    frame_count = 0

    while cap.isOpened():
        ret, frame = cap.read()
        if not ret:
            break

        # Resize frame for faster processing
        frame = cv2.resize(frame, (640, 480))

        # Skip frames
        if frame_count % skip_frames == 0:
            # YOLO object detection
            blob = cv2.dnn.blobFromImage(frame, 1/255.0, (416, 416), swapRB=True, crop=False)
            net.setInput(blob)
            layer_names = net.getUnconnectedOutLayersNames()
            detections = net.forward(layer_names)

            current_bboxes = []
            accident_bboxes = []

            # Loop through YOLO detections
            for detection in detections:
                for object_detected in detection:
                    scores = object_detected[5:]
                    class_id = np.argmax(scores)
                    confidence = scores[class_id]

                    # Filter detections by vehicle class and confidence threshold
                    if confidence > 0.5 and classes[class_id] in vehicle_classes:
                        box = object_detected[0:4] * np.array([frame.shape[1], frame.shape[0], frame.shape[1], frame.shape[0]])
                        (centerX, centerY, width, height) = box.astype("int")
                        x = int(centerX - (width / 2))
                        y = int(centerY - (height / 2))
                        current_bboxes.append((x, y, int(width), int(height)))

            # Check for collisions
            for bbox in current_bboxes:
                for prev_bbox in previous_bboxes:
                    if check_collision(prev_bbox, bbox):
                        accident_bboxes.append(bbox)
                        break

            # Draw bounding boxes
            for bbox in current_bboxes:
                color = (0, 255, 0)  # Default to green
                if bbox in accident_bboxes:
                    color = (0, 0, 255)  # Red for collisions
                x, y, w, h = bbox
                cv2.rectangle(frame, (x, y), (x + w, y + h), color, 2)

            # Detect lanes
            frame = detect_lanes(frame)

            # Update the previous bounding boxes
            previous_bboxes = current_bboxes

        # Display the frame
        cv2.imshow("Vehicle Detection", frame)
        if cv2.waitKey(1) & 0xFF == ord('q'):
            break

        frame_count += 1

    cap.release()
    cv2.destroyAllWindows()

def check_collision(bbox1, bbox2):
    x1, y1, w1, h1 = bbox1
    x2, y2, w2, h2 = bbox2

    x1_min, x1_max = x1, x1 + w1
    y1_min, y1_max = y1, y1 + h1
    x2_min, x2_max = x2, x2 + w2
    y2_min, y2_max = y2, y2 + h2

    overlap = not (x1_max < x2_min or x2_max < x1_min or y1_max < y2_min or y2_max < y1_min)
    return overlap

# Example usage
detect_vehicles_and_accidents(r"C:\Users\yugan\Downloads\80395-572395743_medium.mp4")
